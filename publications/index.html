<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Publications - Xu Guangning</title>
  <meta name="description" content="Academic webpage of Dr. Xu Guangning">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="/publications/">
  <link rel="shortcut icon" type ="image/x-icon" href="/favicon.ico">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  <link rel="preconnect" href="https://player.vimeo.com">
  <link rel="preconnect" href="https://i.vimeocdn.com">
  <link rel="preconnect" href="https://f.vimeocdn.com">



<!-- Google Analytics (original) -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-TEEXQM742D', 'auto');
  ga('send', 'pageview');

</script>

<!-- Global site tag (gtag.js) - Google Analytics 4 -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>

<!-- Google Tag Manager -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TEEXQM742D"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-TEEXQM742D');
</script>
<!-- End Google Tag Manager -->

<!-- Google Tag Manager
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','G-TEEXQM742D');</script>
End Google Tag Manager -->



<script>
MathJax = {
    tex: {
    inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
    tags: 'ams'  // should be 'ams', 'none', or 'all' }. This line makes the equation numbering and labeling work
    }, 
    svg: {
    fontCache: 'global'
    }
};
</script>
<script
    type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script> 

</head>


  <body>

    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-TEEXQM742D"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<nav class="navbar sticky-top navbar-expand-md navbar-dark bg-primary">
    <a class="navbar-brand" href="/">
     <img src="/favicon.ico" width="30" height="30" style="margin-right:5px" class="d-inline-block align-top" alt="">
      Xu Guangning
    </a>
    <button class="toggler navbar-toggler collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarColor02">
        <div class="navbar-nav mr-auto">
            <a class="nav-item nav-link" href="/">Home</a>
                   
                <a class="nav-item nav-link" href="/about">About</a>
                   
                <a class="nav-item nav-link" href="/publications">Publications</a>
                   
                <a class="nav-item nav-link" href="/research">Research</a>
                   
                <a class="nav-item nav-link" href="/teaching">Teaching</a>
            
        </div>
    </div>
</nav>


    <div class="container-fluid">
      <div class="row">
        <div id="gridid" class="col-sm-12 col-xs-12">
  <style>
.jumbotron{
    padding:3%;
    padding-bottom:10px;
    padding-top:10px;
    margin-top:10px;
    margin-bottom:30px;
}
</style>

<!-- 
<div class="jumbotron">
### Preprints
<ol class="bibliography" reversed="reversed"></ol>
</div>
-->
<div class="jumbotron">
  <h3 id="preprint-articles">Preprint articles</h3>
  <ol class="bibliography" reversed="reversed"><li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="zhang2025genft">Zhang, B., <b>Xu, G.</b><b>*</b>, &amp; Ng, M. K. (2025). GenFT: A Generative Parameter-Efficient Fine-Tuning Method for Pretrained Foundation Models. In <i>arXiv preprint arXiv:2506.11042</i>.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexzhang2025genft()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractzhang2025genft()">ABSTRACT</button>



<a href="https://arxiv.org/abs/2506.11042" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>




<div id="azhang2025genft" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@preprint{zhang2025genft,
  title = {GenFT: A Generative Parameter-Efficient Fine-Tuning Method for Pretrained Foundation Models},
  author = {Zhang, Baoquan and Xu, Guangning and Ng, Michael K},
  journal = {arXiv preprint arXiv:2506.11042},
  paperurl = {https://arxiv.org/abs/2506.11042},
  corresponding = {Xu, G.},
  year = {2025}
}
</pre>
</div>


<div id="bzhang2025genft" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Pretrained Foundation Models (PFMs) have transformed numerous applications by enabling efficient adaptation to customized tasks. Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient alternative to full fine-tuning, especially leveraging reparameterized weights ΔW to adapt models for downstream tasks. However, a critical yet underexplored question remains: can we utilize well-pretrained weights W0 to guide the update of task-specific ΔW, avoiding inefficient training it from scratch? To end this, we propose Generative Parameter-Efficient Fine-Tuning (GenFT), a novel method that extracts structured, transferable information from W0 for efficient ΔW training. To extract row and column structure information, GenFT applies row and column transformations to distill essential patterns from W0. A tailored policy further decomposes ΔW into layer-shared and layer-specific components, balancing information reuse and individualized flexibility. GenFT is simple yet effective, achieving superior performance across CV and NLP tasks. Extensive experiments on VTAB-1K, FGVC, and GLUE benchmarks demonstrate that GenFT outperforms state-of-the-art PEFT methods, offering a new perspective for efficient model adaptation.</pre>
</div>

<script>
function toggleBibtexzhang2025genft(parameter) {
    var x= document.getElementById('azhang2025genft');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractzhang2025genft(parameter) {
    var x= document.getElementById('bzhang2025genft');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li></ol>
</div>

<div class="jumbotron">
  <h3 id="refereed-journal-articles">Refereed journal articles</h3>
  <ol class="bibliography" reversed="reversed"><li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="xu2024tls"><b>Xu, G.</b>, Ng, M. K.<b>*</b>, Ye, Y.<b>*</b>, Li, X., Song, G., Zhang, B., &amp; Huang, Z. (2024). TLS-MWP: A Tensor-based Long-and Short-range Convolution for Multiple Weather Prediction. <i>IEEE Transactions on Circuits and Systems for Video Technology</i>, <i>34</i>(9), 8382–8397.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexxu2024tls()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractxu2024tls()">ABSTRACT</button>



<a href="https://ieeexplore.ieee.org/document/10475377/" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/TLS_MWP" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="axu2024tls" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{xu2024tls,
  title = {TLS-MWP: A Tensor-based Long-and Short-range Convolution for Multiple Weather Prediction},
  author = {Xu, Guangning and Ng, Michael K and Ye, Yunming and Li, Xutao and Song, Ge and Zhang, Bowen and Huang, Zhichao},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {34},
  number = {9},
  pages = {8382-8397},
  paperurl = {https://ieeexplore.ieee.org/document/10475377/},
  codeurl = {https://github.com/xuguangning1218/TLS_MWP},
  corresponding = {Ng, M. K.; Ye, Y.},
  year = {2024}
}
</pre>
</div>


<div id="bxu2024tls" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Weather prediction plays a crucial role in human development. Recently, deep learning has demonstrated promising prospects in weather forecasting by integrating convolutional neural networks (CNNs) and recurrent neural networks (RNNs). However, two main challenges still exist in multiple weather condition prediction. The first challenge considers multiple weather condition correlations in predictions. The second challenge is how to model long- and short-range spatial dependencies under multiple weather conditions. A novel operator named as tensor-based long- and short-range convolution (TLS-Conv) is proposed to address these challenges. Within this operator, the node &amp; relation attention is utilized to identify the contributions of spatial grid points and weather conditions for prediction. Additionally, the adaptive tensor graph convolution (ATGCN) is tailored to dynamically capture long-range spatial dependencies within multiple weather conditions. Finally, the traditional convolution is integrated with the ATGCN to model both long- and short-range spatial dependencies and weather condition correlations. Building upon the TLS-Conv, the tensor-based long- and short-range convolution for multiple weather prediction (TLS-MWP) model is proposed to predict multiple weather conditions. Extensive experiments are conducted under real-world weather conditions to evaluate its performance. These results unequivocally demonstrate that TLS-MWP surpasses previous methods. The code is available on GitHub at: https://github.com/xuguangning1218/TLS_MWP.</pre>
</div>

<script>
function toggleBibtexxu2024tls(parameter) {
    var x= document.getElementById('axu2024tls');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractxu2024tls(parameter) {
    var x= document.getElementById('bxu2024tls');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="XU2024FHDTIE"><b>Xu, G.</b>, Ng, M. K.<b>*</b>, Ye, Y., &amp; Zhang, B.<b>*</b> (2024). FHDTIE: Fine-grained Heterogeneous Data Fusion for Tropical Cyclone Intensity Estimation. <i>IEEE Transactions on Geoscience and Remote Sensing</i>.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexXU2024FHDTIE()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractXU2024FHDTIE()">ABSTRACT</button>



<a href="#" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/FHDTIE" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="aXU2024FHDTIE" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{XU2024FHDTIE,
  title = {FHDTIE: Fine-grained Heterogeneous Data Fusion for Tropical Cyclone Intensity Estimation},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Xu, Guangning and Ng, Michael K and Ye, Yunming and Zhang, Bowen},
  paperurl = {#},
  codeurl = {https://github.com/xuguangning1218/FHDTIE},
  corresponding = {Ng, M. K.; Zhang, B.},
  year = {2024}
}
</pre>
</div>


<div id="bXU2024FHDTIE" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>A tropical cyclone is a highly destructive extreme weather phenomenon. Estimating intensity of a tropical cyclone can help provide early warnings, guiding specific disaster defense measures. However, two main challenges hinder performance improvement. The first challenge is how to combine heterogeneous tropical cyclone data into a latent space so that the model can leverage the cloud structure of satellite imagery and the comprehensive meteorological information from reanalysis and forecast data for intensity estimation. The second challenge lies in detecting multiple pseudo fine-grained areas for the final estimation, since tropical cyclones are highly diverse extreme weather phenomena. Neglecting any of these pseudo fine-grained areas or relying solely on a single one can potentially result in subpar estimation performance. To address challenges mentioned above, a fine-grained heterogeneous data fusion framework named FHDTIE is proposed. Two key components in this framework can address the aforementioned challenges. One component is the Heterogeneous Data Fuser (HDF), which offers shape matching and channel fusing strategies for heterogeneous data fusion. The other component is called Fine-grained Cluster Features Integrator (FCFI). It utilizes a clustering method to identify multiple pseudo fine-grained areas. Within these areas, the U-Net is used to automatically learn pseudo fine-grained area representations, and then the Graph Neural Network handles information interaction across these representations. Extensive experiments were conducted to demonstrate the robustness and superiority of the proposed fine-grained heterogeneous data fusion framework. The code is available at GitHub: https://github.com/xuguangning1218/FHDTIE.</pre>
</div>

<script>
function toggleBibtexXU2024FHDTIE(parameter) {
    var x= document.getElementById('aXU2024FHDTIE');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractXU2024FHDTIE(parameter) {
    var x= document.getElementById('bXU2024FHDTIE');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="lin2023spherical">Lin, K., Li, X.<b>*</b>, Ye, Y., Feng, S., Zhang, B., <b>Xu, G.</b>, &amp; Wang, Z. (2023). Spherical Neural Operator Network for Global Weather Prediction. <i>IEEE Transactions on Circuits and Systems for Video Technology</i>.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexlin2023spherical()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractlin2023spherical()">ABSTRACT</button>



<a href="https://ieeexplore.ieee.org/abstract/document/10335752" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>




<div id="alin2023spherical" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{lin2023spherical,
  title = {Spherical Neural Operator Network for Global Weather Prediction},
  author = {Lin, Kenghong and Li, Xutao and Ye, Yunming and Feng, Shanshan and Zhang, Baoquan and Xu, Guangning and Wang, Ziye},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  paperurl = {https://ieeexplore.ieee.org/abstract/document/10335752},
  corresponding = {Li, X.},
  year = {2023}
}
</pre>
</div>


<div id="blin2023spherical" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Global weather forecast is an important spatial-temporal prediction problem, which can provide numerous societal benefits such as extreme weather forewarning, traffic scheduling, and agricultural planning. Though many spatial-temporal prediction models have been proposed, they suffer from two drawbacks for global weather forecasts, namely 1) ignoring the physical mechanism and spherical characteristics and 2) not effectively exploiting the global and local correlations. To address the above drawbacks, in this paper, we formalize global weather state dynamics as partial differential equations (PDEs) in spherical space and infer the state of the global weather system by solving these PDEs. Specifically, we use Green’s function method to solve the PDEs and find that the solution of the spherical PDEs can be obtained by the spherical convolution. We further proposed a novel Spherical Neural Operator, SNO, which consists of spherical convolution and vanilla convolution. The former is used to solve these PDEs and model the global correlations in spherical space, and the latter is used to capture the local correlations. Upon the operator, a global weather prediction model is developed. Extensive experimental results demonstrate the effectiveness and superiority of our method over state-of-the-art approaches.</pre>
</div>

<script>
function toggleBibtexlin2023spherical(parameter) {
    var x= document.getElementById('alin2023spherical');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractlin2023spherical(parameter) {
    var x= document.getElementById('blin2023spherical');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="xu2023tfg"><b>Xu, G.</b>, Li, Y.<b>*</b>, Ma, C., Li, X., Ye, Y., Lin, Q., Huang, Z., &amp; Chen, S. (2023). TFG-Net: Tropical Cyclone Intensity Estimation from a Fine-grained perspective with the Graph convolution neural network. <i>Engineering Applications of Artificial Intelligence</i>, <i>118</i>, 105673.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexxu2023tfg()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractxu2023tfg()">ABSTRACT</button>



<a href="https://www.sciencedirect.com/science/article/pii/S0952197622006637" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/TI_Estimation" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="axu2023tfg" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{xu2023tfg,
  title = {TFG-Net: Tropical Cyclone Intensity Estimation from a Fine-grained perspective with the Graph convolution neural network},
  author = {Xu, Guangning and Li, Yan and Ma, Chi and Li, Xutao and Ye, Yunming and Lin, Qingquan and Huang, Zhichao and Chen, Shidong},
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {118},
  pages = {105673},
  paperurl = {https://www.sciencedirect.com/science/article/pii/S0952197622006637},
  codeurl = {https://github.com/xuguangning1218/TI_Estimation},
  corresponding = {Li, Y.},
  year = {2023}
}
</pre>
</div>


<div id="bxu2023tfg" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Tropical Cyclone Intensity Estimation (TIE) is a fundamental study subject for tropical cyclone development, flood or landslide avoidance, etc. Despite considerable efforts, two main challenges remain unresolved in this critical endeavor. The first challenge is that the TIE task is frequently conducted as a coarse-grained recognition problem rather than a fine-grained one. The second challenge is that the prediction fails to consider general wind speed information. To conquer these two challenges, we offer a novel model, namely Tropical cyclone intensity estimation from a Fine-grained perspective with the Graph convolution neural Network (TFG-Net). It is composed of three key components, viz., the Backbone, the Fine-grained Tropical cyclone Features Extractor (FTFE), and the Wind Scale Transition Rule Generator (WTRG), which aim at extracting general spatial features, subtle spatial features, and general wind speed information, respectively. To validate the proposed method, extensive experiments on a well-known real-world tropical dataset named GridSat were carried out. Following the standard benchmark task setting that the model estimates the wind speed from a given satellite image, the proposed TFG-Net reaches 11.12 knots in the RMSE metric, which outperforms 33.33%, 2.54% to the traditional method and the state-of-the-art deep learning method, respectively. The code is available on GitHub:https://github.com/xuguangning1218/TI_Estimation and its reproductive result is available on Code Ocean: https://doi.org/10.24433/CO.6606867.v1.</pre>
</div>

<script>
function toggleBibtexxu2023tfg(parameter) {
    var x= document.getElementById('axu2023tfg');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractxu2023tfg(parameter) {
    var x= document.getElementById('bxu2023tfg');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="li2023multi">Li, X., Ng, M. K., <b>Xu, G.</b>, &amp; Yip, A<b>*</b>. (2023). Multi-relational graph convolutional networks: Generalization guarantees and experiments. <i>Neural Networks</i>, <i>161</i>, 343–358.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexli2023multi()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractli2023multi()">ABSTRACT</button>



<a href="https://www.sciencedirect.com/science/article/pii/S0893608023000576" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>




<div id="ali2023multi" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{li2023multi,
  title = {Multi-relational graph convolutional networks: Generalization guarantees and experiments},
  author = {Li, Xutao and Ng, Michael K and Xu, Guangning and Yip, Andy},
  journal = {Neural Networks},
  volume = {161},
  pages = {343--358},
  paperurl = {https://www.sciencedirect.com/science/article/pii/S0893608023000576},
  corresponding = {Yip, A},
  year = {2023}
}
</pre>
</div>


<div id="bli2023multi" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>The class of multi-relational graph convolutional networks (MRGCNs) is a recent extension of standard graph convolutional networks (GCNs) to handle heterogenous graphs with multiple types of relationships. MRGCNs have been shown to yield results superior than traditional GCNs in various machine learning tasks. The key idea is to introduce a new kind of convolution operated on tensors that can effectively exploit correlations exhibited in multiple relationships. The main objective of this paper is to analyze the algorithmic stability and generalization guarantees of MRGCNs to confirm the usefulness of MRGCNs. Our contributions are of three folds. First, we develop a matrix representation of various tensor operations underneath MRGCNs to simplify the analysis significantly. Next, we prove the uniform stability of MRGCNs and deduce the convergence of the generalization gap to support the usefulness of MRGCNs. The analysis sheds lights on the design of MRGCNs, for instance, how the data should be scaled to achieve the uniform stability of the learning process. Finally, we provide experimental results to demonstrate the stability results.</pre>
</div>

<script>
function toggleBibtexli2023multi(parameter) {
    var x= document.getElementById('ali2023multi');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractli2023multi(parameter) {
    var x= document.getElementById('bli2023multi');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="huang2023multi">Huang, Z., Li, X.<b>*</b>, Ye, Y.<b>*</b>, Zhang, B., <b>Xu, G.</b>, &amp; Gan, W. (2023). Multi-view knowledge graph fusion via knowledge-aware attentional graph neural network. <i>Applied Intelligence</i>, <i>53</i>(4), 3652–3671.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexhuang2023multi()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstracthuang2023multi()">ABSTRACT</button>



<a href="https://www.sciencedirect.com/science/article/pii/S0893608023000576" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>




<div id="ahuang2023multi" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{huang2023multi,
  title = {Multi-view knowledge graph fusion via knowledge-aware attentional graph neural network},
  author = {Huang, Zhichao and Li, Xutao and Ye, Yunming and Zhang, Baoquan and Xu, Guangning and Gan, Wensheng},
  journal = {Applied Intelligence},
  volume = {53},
  number = {4},
  pages = {3652--3671},
  paperurl = {https://www.sciencedirect.com/science/article/pii/S0893608023000576},
  corresponding = {Li, X.; Ye, Y.},
  year = {2023}
}
</pre>
</div>


<div id="bhuang2023multi" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>The class of multi-relational graph convolutional networks (MRGCNs) is a recent extension of standard graph convolutional networks (GCNs) to handle heterogenous graphs with multiple types of relationships. MRGCNs have been shown to yield results superior than traditional GCNs in various machine learning tasks. The key idea is to introduce a new kind of convolution operated on tensors that can effectively exploit correlations exhibited in multiple relationships. The main objective of this paper is to analyze the algorithmic stability and generalization guarantees of MRGCNs to confirm the usefulness of MRGCNs. Our contributions are of three folds. First, we develop a matrix representation of various tensor operations underneath MRGCNs to simplify the analysis significantly. Next, we prove the uniform stability of MRGCNs and deduce the convergence of the generalization gap to support the usefulness of MRGCNs. The analysis sheds lights on the design of MRGCNs, for instance, how the data should be scaled to achieve the uniform stability of the learning process. Finally, we provide experimental results to demonstrate the stability results.</pre>
</div>

<script>
function toggleBibtexhuang2023multi(parameter) {
    var x= document.getElementById('ahuang2023multi');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstracthuang2023multi(parameter) {
    var x= document.getElementById('bhuang2023multi');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="luo2022reconstitution">Luo, C., <b>Xu, G.</b>, Li, X.<b>*</b>, &amp; Ye, Y.<b>*</b> (2022). The reconstitution predictive network for precipitation nowcasting. <i>Neurocomputing</i>, <i>507</i>, 1–15.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexluo2022reconstitution()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractluo2022reconstitution()">ABSTRACT</button>



<a href="https://www.sciencedirect.com/science/article/pii/S0925231222009195" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/luochuyao/RST_LSTM" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="aluo2022reconstitution" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{luo2022reconstitution,
  title = {The reconstitution predictive network for precipitation nowcasting},
  author = {Luo, Chuyao and Xu, Guangning and Li, Xutao and Ye, Yunming},
  journal = {Neurocomputing},
  volume = {507},
  pages = {1--15},
  paperurl = {https://www.sciencedirect.com/science/article/pii/S0925231222009195},
  codeurl = {https://github.com/luochuyao/RST_LSTM},
  corresponding = {Li, X.; Ye, Y.},
  year = {2022}
}
</pre>
</div>


<div id="bluo2022reconstitution" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Precipitation nowcasting is an indispensable task for traffic routing and disaster avoidance. Due to its strenuous movement, even the most recent deep learning techniques in computer vision deliver unsatisfactory performance. The main reason can be attributed to the following two aspects: 1) The traditional convolution in the input has a limited field to extract spatial representation. 2) The convolution in state-to-state connection might lead to mismatch problems and inaccurate strength predictions. To address the two drawbacks, we propose an innovative algorithm the Reconstitute Spatiotemporal LSTM (RST-LSTM) based on Convolutional Recurrent Neural Network (ConvRNN). In the proposed model, we present the local and global reconstitution scheme into the current input and the hidden state respectively. The local reconstitution (LR) can adaptively adjust the perceptual field of convolution so as to extract more useful spatial information and exclude invalid representation. Moreover, in the hidden state, the global reconstitution (GR) is embedded to alleviate the problem of mismatching between the current input and hidden state. Experimental results in MovingMNIST++ show that our approach can achieve the best predictions for those data with more drastic changes in the adjacent time. For radar data in CIKM AnalytiCup 2017 (we name it RadarCIKM in this paper), our method outperforms the state-of-the-art competitors. Furthermore, we notice that GR can promote the nowcasting in the high radar echo region and LR can reduce the error.</pre>
</div>

<script>
function toggleBibtexluo2022reconstitution(parameter) {
    var x= document.getElementById('aluo2022reconstitution');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractluo2022reconstitution(parameter) {
    var x= document.getElementById('bluo2022reconstitution');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="xu2022ls"><b>Xu, G.</b>, Li, X., Feng, S., Ye, Y.<b>*</b>, Tu, Z., Lin, K., &amp; Huang, Z. (2022). LS-NTP: Unifying long-and short-range spatial correlations for near-surface temperature prediction. <i>Neural Networks</i>, <i>155</i>, 242–257.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexxu2022ls()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractxu2022ls()">ABSTRACT</button>



<a href="https://www.sciencedirect.com/science/article/pii/S0893608022002787" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/LS_NTP" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="axu2022ls" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{xu2022ls,
  title = {LS-NTP: Unifying long-and short-range spatial correlations for near-surface temperature prediction},
  author = {Xu, Guangning and Li, Xutao and Feng, Shanshan and Ye, Yunming and Tu, Zhihua and Lin, Kenghong and Huang, Zhichao},
  journal = {Neural Networks},
  volume = {155},
  pages = {242--257},
  paperurl = {https://www.sciencedirect.com/science/article/pii/S0893608022002787},
  codeurl = {https://github.com/xuguangning1218/LS_NTP},
  corresponding = {Ye, Y.},
  year = {2022}
}
</pre>
</div>


<div id="bxu2022ls" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>The near-surface temperature prediction (NTP) is an important spatial–temporal forecast problem, which can be used to prevent temperature crises. Most of the previous approaches fail to explicitly model the long- and short-range spatial correlations simultaneously, which is critical to making an accurate temperature prediction. In this study, both long- and short-range spatial correlations are captured to fill this gap by a novel convolution operator named Long- and Short-range Convolution (LS-Conv). The proposed LS-Conv operator includes three key components, namely, Node-based Spatial Attention (NSA), Long-range Adaptive Graph Constructor (LAGC), and Long- and Short-range Integrator (LSI). To capture long-range spatial correlations, NSA and LAGC are proposed to evaluate node importance aiming at auto-constructing long-range spatial correlations, which is named as Long-range aware Graph Convolution Network (LR-GCN). After that, the Short-range aware Convolution Neural Network (SR-CNN) accounts for the short-range spatial correlations. Finally, LSI is proposed to capture both long- and short-range spatial correlations by intra-unifying LR-GCN and SR-CNN. Upon the proposed LS-Conv operator, a new model called Long- and Short-range for NPT (LS-NTP) is developed. Extensive experiments are conducted on two real-world datasets and the results demonstrate that the proposed method outperforms state-of-the-art techniques. The source code is available on GitHub:https://github.com/xuguangning1218/LS_NTP.</pre>
</div>

<script>
function toggleBibtexxu2022ls(parameter) {
    var x= document.getElementById('axu2022ls');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractxu2022ls(parameter) {
    var x= document.getElementById('bxu2022ls');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="xu2022saf"><b>Xu, G.</b>, Lin, K., Li, X.<b>*</b>, &amp; Ye, Y.<b>*</b> (2022). SAF-Net: A spatio-temporal deep learning method for typhoon intensity prediction. <i>Pattern Recognition Letters</i>, <i>155</i>, 121–127.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexxu2022saf()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractxu2022saf()">ABSTRACT</button>



<a href="https://www.sciencedirect.com/science/article/pii/S0167865521004037" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/TI_Prediction" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="axu2022saf" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{xu2022saf,
  title = {SAF-Net: A spatio-temporal deep learning method for typhoon intensity prediction},
  author = {Xu, Guangning and Lin, Kenghong and Li, Xutao and Ye, Yunming},
  journal = {Pattern Recognition Letters},
  volume = {155},
  pages = {121--127},
  paperurl = {https://www.sciencedirect.com/science/article/pii/S0167865521004037},
  codeurl = {https://github.com/xuguangning1218/TI_Prediction},
  corresponding = {Li, X.; Ye, Y.},
  year = {2022}
}
</pre>
</div>


<div id="bxu2022saf" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>A typhoon is a destructive weather system that can cause severe casualties and economic losses. Typhoon intensity (TI) is a measurement to evaluate its ruinous degree. Hence, typhoon intensity prediction is an important research problem and many methods have been proposed. However, most of the existing approaches have very limited capability to combine the 2D Typhoon Structure Domain-expert Knowledge (2D-TSDK) and the 3D Typhoon Structure Data-driven Knowledge (3D-TSDK) for the TI prediction. To address this issue, this paper proposes a spatio-temporal deep learning method named Spatial Attention Fusing Network (SAF-Net). The designed model aims to fuse the 2D-TSDK and the 3D-TSDK by developing a specific Wide &amp; Deep framework. In the data-driven component, a special Spatial Attention (SA) module is designed to automatically select high-response wind speed areas and embedded into a three-branch CNN to exploit the 3D-TSDK. Then, the Wide &amp; Deep framework integrates the 2D-TSDK and the 3D-TSDK for the TI prediction. Comprehensive experiments have been conducted on a real-world dataset, and the result shows that the proposed method outperforms state-of-the-art typhoon intensity prediction methods. The code is available in GitHub:https://github.com/xuguangning1218/TI_Prediction.</pre>
</div>

<script>
function toggleBibtexxu2022saf(parameter) {
    var x= document.getElementById('axu2022saf');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractxu2022saf(parameter) {
    var x= document.getElementById('bxu2022saf');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="xu2022convgru"><b>Xu, G.</b>, Xian, D.<b>*</b>, Fournier-Viger, P., Li, X.<b>*</b>, Ye, Y., &amp; Hu, X. (2022). AM-ConvGRU: A spatio-temporal model for typhoon path prediction. <i>Neural Computing and Applications</i>, <i>34</i>(8), 5905–5921.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexxu2022convgru()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractxu2022convgru()">ABSTRACT</button>



<a href="https://link.springer.com/article/10.1007/s00521-021-06724-x" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/Typhoon_Path" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="axu2022convgru" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@article{xu2022convgru,
  title = {AM-ConvGRU: A spatio-temporal model for typhoon path prediction},
  author = {Xu, Guangning and Xian, Di and Fournier-Viger, Philippe and Li, Xutao and Ye, Yunming and Hu, Xiuqing},
  journal = {Neural Computing and Applications},
  volume = {34},
  number = {8},
  pages = {5905--5921},
  paperurl = {https://link.springer.com/article/10.1007/s00521-021-06724-x},
  codeurl = {https://github.com/xuguangning1218/Typhoon_Path},
  corresponding = {Xian, D.; Li, X.},
  year = {2022}
}
</pre>
</div>


<div id="bxu2022convgru" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Typhoons are one of the most destructive types of disasters. Several statistical models have been designed to predict their paths to reduce damage, casualties, and economic loss. To further increase prediction accuracy, two key challenges are (1) to extract better nonlinear 3D features of typhoons, which is hard due to their complex high-dimensional properties, and (2) to combine suitable 2D and 3D features in a proper way to improve predictions. To address these challenges, this paper presents a novel spatio-temporal deep learning model named Attention-based Multi ConvGRU (AM-ConvGRU). To automatically select high response isobaric planes of typhoons when considering their whole 3D structures, AM-ConvGRU leverages the Residual Channel Attention Block (RCAB). Furthermore, it integrates a novel model named Multi-ConvGRU to extract large-scale nonlinear spatial features of typhoons. Moreover, the approach relies on a Wide &amp; Deep framework to fuse the traditional Generalized Linear Model (GLM) with the proposed AM-ConvGRU model. To evaluate the designed approach, extensive experiments have been conducted using real-world typhoons data from the Western North Pacific (WNP) basin obtained from both the China Meteorological Administration (CMA) dataset and the EAR-Interim dataset maintained by the European Centre for Medium-Range Weather Forecasts (ECMWF). Results show that the proposed method outperforms state-of-the-art deep learning typhoon prediction methods. The source code is available on GitHub with the following link:https://github.com/xuguangning1218/Typhoon_Path.</pre>
</div>

<script>
function toggleBibtexxu2022convgru(parameter) {
    var x= document.getElementById('axu2022convgru');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractxu2022convgru(parameter) {
    var x= document.getElementById('bxu2022convgru');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li></ol>
</div>

<div class="jumbotron">
  <h3 id="refereed-conference-proceedings">Refereed conference proceedings</h3>
  <ol class="bibliography" reversed="reversed"><li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="ding2024edda">Ding, D., Dong, L., Huang, Z., <b>Xu, G.</b>, Huang, X., Liu, B., Jing, L., &amp; Zhang, B<b>*</b>. (2024). EDDA: A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection. <i>Proceedings of the 30th International Conference on Computational Linguistics (COLING)</i>.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexding2024edda()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractding2024edda()">ABSTRACT</button>



<a href="https://arxiv.org/abs/2403.15715" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/Szu-Ddj/EDDA" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="ading2024edda" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@inproceedings{ding2024edda,
  title = {EDDA: A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection},
  author = {Ding, Daijun and Dong, Li and Huang, Zhichao and Xu, Guangning and Huang, Xu and Liu, Bo and Jing, Liwen and Zhang, Bowen},
  booktitle = {Proceedings of the 30th International Conference on Computational Linguistics (COLING)},
  paperurl = {https://arxiv.org/abs/2403.15715},
  codeurl = {https://github.com/Szu-Ddj/EDDA},
  corresponding = {Zhang, B},
  year = {2024}
}
</pre>
</div>


<div id="bding2024edda" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Stance detection aims to determine the attitude expressed in text towards a given target. Zero-shot stance detection (ZSSD) has emerged to classify stances towards unseen targets during inference. Recent data augmentation techniques for ZSSD increase transferable knowledge between targets through text or target augmentation. However, these methods exhibit limitations. Target augmentation lacks logical connections between generated targets and source text, while text augmentation relies solely on training data, resulting in insufficient generalization. To address these issues, we propose an encoder-decoder data augmentation (EDDA) framework. The encoder leverages large language models and chain-of-thought prompting to summarize texts into target-specific if-then rationales, establishing logical relationships. The decoder generates new samples based on these expressions using a semantic correlation word replacement strategy to increase syntactic diversity. We also analyze the generated expressions to develop a rationale-enhanced network that fully utilizes the augmented data. Experiments on benchmark datasets demonstrate our approach substantially improves over state-of-the-art ZSSD techniques. The proposed EDDA framework increases semantic relevance and syntactic variety in augmented texts while enabling interpretable rationale-based learning.</pre>
</div>

<script>
function toggleBibtexding2024edda(parameter) {
    var x= document.getElementById('ading2024edda');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractding2024edda(parameter) {
    var x= document.getElementById('bding2024edda');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="xu2023int"><b>Xu, G.</b>, Yang, J., Guo, J., Huang, Z.<b>*</b>, &amp; Zhang, B.<b>*</b> (2023). Int-GNN: A user intention aware graph neural network for session-based recommendation. <i>ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, 1–5.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexxu2023int()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractxu2023int()">ABSTRACT</button>



<a href="https://ieeexplore.ieee.org/document/10097031" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>


<a href="https://github.com/xuguangning1218/IntGNN_ICASSP2023" target="_blank"><button class="btn btn-info btm-sm">Code</button></a>



<div id="axu2023int" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@inproceedings{xu2023int,
  title = {Int-GNN: A user intention aware graph neural network for session-based recommendation},
  author = {Xu, Guangning and Yang, Jinyang and Guo, Jinjin and Huang, Zhichao and Zhang, Bowen},
  booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {1--5},
  paperurl = {https://ieeexplore.ieee.org/document/10097031},
  codeurl = {https://github.com/xuguangning1218/IntGNN_ICASSP2023},
  corresponding = {Huang, Z.; Zhang, B.},
  year = {2023}
}
</pre>
</div>


<div id="bxu2023int" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Session-Based Recommendation (SBR) is a spotlight research problem. Although many efforts have been made, challenges still exist. The key to unlocking this shackle is the user intention, an intuitive but hard-to-model concept in the anonymous session. Unlike previous research, we suggest mining potential user intention by counting the number of item occurrences in a user session and considering the long interval between item re-interactions. Beyond these, we take user preference, a biased user intention, into account in the prediction stage. Forming these together, we propose a model named user Intention aware Graph Neural Network (Int-GNN) aiming at capturing user intention. Extensive experiments have been conducted on three real-world datasets, and the results show the superiority of our method. The code is available on GitHub: https://github.com/xuguangning1218/IntGNN_ICASSP2023</pre>
</div>

<script>
function toggleBibtexxu2023int(parameter) {
    var x= document.getElementById('axu2023int');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractxu2023int(parameter) {
    var x= document.getElementById('bxu2023int');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="zhang2023twitter">Zhang, B<b>*</b>., Ding, D., <b>Xu, G.</b><b>*</b>, Guo, J., Huang, Z., &amp; Huang, X. (2023). Twitter stance detection via neural production systems. <i>ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, 1–5.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexzhang2023twitter()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractzhang2023twitter()">ABSTRACT</button>



<a href="https://ieeexplore.ieee.org/document/10094597" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>




<div id="azhang2023twitter" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@inproceedings{zhang2023twitter,
  title = {Twitter stance detection via neural production systems},
  author = {Zhang, Bowen and Ding, Daijun and Xu, Guangning and Guo, Jinjin and Huang, Zhichao and Huang, Xu},
  booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {1--5},
  paperurl = {https://ieeexplore.ieee.org/document/10094597},
  corresponding = {Xu, G.; Zhang, B},
  year = {2023}
}
</pre>
</div>


<div id="bzhang2023twitter" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Stance detection is an important task, which aims to classify the attitude of an opinionated text toward a given target. In this paper, we develop an interpretable neural production system for stance detection (NPS4SD). NPS4SD is an end-to-end deep learning model, which consists of a set of knowledge rules that are applied by binding with specific entities. NPS4SD consists of two main components: a pretrained model for learning the text representation and a variable binding network (VBN) to bind the knowledge rules with text entities. Extensive experiments are conducted to evaluate the effectiveness of the proposed NPS4SD model on three real-world datasets with in-domain, cross-target and zero-shot setups. Experimental results demonstrate that NPS4SD achieves substantially better performance than the strong competitors for the stance detection task.</pre>
</div>

<script>
function toggleBibtexzhang2023twitter(parameter) {
    var x= document.getElementById('azhang2023twitter');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractzhang2023twitter(parameter) {
    var x= document.getElementById('bzhang2023twitter');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><style>
.btn{
    margin-bottom:5px;
    padding-top:0px;
    padding-bottom:0px;
    padding-left:15px;
    padding-right:15px;
    height:20px
}

pre{
    white-space: pre-wrap;  
    white-space: -moz-pre-wrap; 
    white-space: -pre-wrap; 
    white-space: -o-pre-wrap; 
    word-wrap: break-word; 
    width:100%; overflow-x:auto;
}
</style>




<!-- 结合原有的replace_first处理，并且应用updated_reference变量 -->
<div class="text-justify"><span id="guo2023knowledge">Guo, J., Huang, Z.<b>*</b>, <b>Xu, G.</b>, Zhang, B., &amp; Duan, C.<b>*</b> (2023). Knowledge-Aware Few Shot Learning for Event Detection from Short Texts. <i>ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, 1–5.</span></div>









<button class="btn btn-danger btm-sm" onclick="toggleBibtexguo2023knowledge()">BIB</button>



<button class="btn btn-warning btm-sm" onclick="toggleAbstractguo2023knowledge()">ABSTRACT</button>



<a href="https://ieeexplore.ieee.org/document/10095891" target="_blank"><button class="btn btn-info btm-sm">Paper</button></a>




<div id="aguo2023knowledge" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>@inproceedings{guo2023knowledge,
  title = {Knowledge-Aware Few Shot Learning for Event Detection from Short Texts},
  author = {Guo, Jinjin and Huang, Zhichao and Xu, Guangning and Zhang, Bowen and Duan, Chaoqun},
  booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {1--5},
  paperurl = {https://ieeexplore.ieee.org/document/10095891},
  corresponding = {Huang, Z.; Duan, C.},
  year = {2023}
}
</pre>
</div>


<div id="bguo2023knowledge" style="display: none; background-color:lightgray; border-radius:5px; padding:10px; margin-bottom:20px;">
<pre>Event detection in a city is crucial for the government to listen to the voice of the citizens, be aware of the real occurrences in a city, and then make wiser policies. However, in reality some important events with few samples are easily to be overwhelmed by the massive information and hard to be recognized, and additionally the limited word description from the short texts even makes the recognition harder. To address the problems, we propose a knowledge-aware event detector by incorporating the external knowledge to detect the events with few examples. The external knowledge incorporation with different semantic relations is capable to enrich the short texts. In addition, we leverage the representative few shot learning framework to formulate the event detection as the text classification problem. The proposed model is evaluated on two widely event-detection datasets. The experiments show a consistent accuracy improvement. The findings validates that our model with the knowledge infusion is effective to detect the few shot events from the short texts.</pre>
</div>

<script>
function toggleBibtexguo2023knowledge(parameter) {
    var x= document.getElementById('aguo2023knowledge');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
function toggleAbstractguo2023knowledge(parameter) {
    var x= document.getElementById('bguo2023knowledge');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li></ol>
</div>

</div>

      </div>
    </div>

    <br/>
<section id="footer">
<div class="container-footer">
  <div class="panel-footer">
	  <div class="row">
		<div class="col-sm-4">
		    <h5>About</h5>	
            <p>Xu Guangning<br/> Research Assistant Professor<br/> Hong Kong Baptist Univerity
</p>
		</div>

		<div class="col-sm-4">
		    <h5>Contact</h5>	
            <p><a href="mailto:guangningxu35@gmail.com" target="_blank"><i class="fa fa-envelope fa-1x"></i> Email Guangning</a> <br/> <a href="https://github.com/xuguangning1218" target="_blank"><i class="fa fa-github fa-1x"></i> Vist Guangning's Github</a>
</p>
		</div>

		<div class="col-sm-4">
		    <h5>Coordinates</h5>	
            <p>FSC1004, Hong Kong Baptist Univerity, Kowloon Tong, Kowloon, Hong Kong, China
</p>
		</div>
	  </div>

      <center><p>&copy 2025 Xu Guangning </p></center>
	</div>
  </div>
</div>

<script src="/assets/javascript/bootstrap/bootstrap.bundle.min.js"></script>


  </body>

</html>
